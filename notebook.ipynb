{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Class']\n",
    "X = df.drop(['Class', 'Id', 'EJ'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BQ\n",
      "CB\n",
      "CC\n",
      "DU\n",
      "EL\n",
      "FC\n",
      "FL\n",
      "FS\n",
      "GL\n"
     ]
    }
   ],
   "source": [
    "for c in X:\n",
    "    if df[c].isnull().any():\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('standard_scale', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_res = num_pipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier(n_estimators=1000, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "model = LogisticRegression(class_weight=\"balanced\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline([\n",
    "    ('num_pipe', num_pipe),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'num_pipe', 'model', 'num_pipe__memory', 'num_pipe__steps', 'num_pipe__verbose', 'num_pipe__num_imputer', 'num_pipe__standard_scale', 'num_pipe__num_imputer__add_indicator', 'num_pipe__num_imputer__copy', 'num_pipe__num_imputer__fill_value', 'num_pipe__num_imputer__keep_empty_features', 'num_pipe__num_imputer__missing_values', 'num_pipe__num_imputer__strategy', 'num_pipe__num_imputer__verbose', 'num_pipe__standard_scale__copy', 'num_pipe__standard_scale__with_mean', 'num_pipe__standard_scale__with_std', 'model__C', 'model__class_weight', 'model__dual', 'model__fit_intercept', 'model__intercept_scaling', 'model__l1_ratio', 'model__max_iter', 'model__multi_class', 'model__n_jobs', 'model__penalty', 'model__random_state', 'model__solver', 'model__tol', 'model__verbose', 'model__warm_start'])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.get_params().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#   'model__n_estimators':[800,900,1000,1100],\n",
    "#   'model__min_samples_split': [2,3,4]\n",
    "#   }\n",
    "\n",
    "# grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=5)\n",
    "# grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Grid Search class\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # make lists of different parameters to check\n",
    "# parameters = {\n",
    "#   'n_estimators':[1,10,100,1000],\n",
    "#   'min_samples_split': [2,3,4,5]\n",
    "#   }\n",
    "# #initialize\n",
    "# grid_pipeline = GridSearchCV(estimator, parameters)\n",
    "# # fit\n",
    "# grid_pipeline.fit(X,y)\n",
    "# grid_pipeline.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "def cross_validation(model, _X, _y, _cv=5):\n",
    "      '''Function to perform 5 Folds Cross-Validation\n",
    "       Parameters\n",
    "       ----------\n",
    "      model: Python Class, default=None\n",
    "              This is the machine learning algorithm to be used for training.\n",
    "      _X: array\n",
    "           This is the matrix of features.\n",
    "      _y: array\n",
    "           This is the target variable.\n",
    "      _cv: int, default=5\n",
    "          Determines the number of folds for cross-validation.\n",
    "       Returns\n",
    "       -------\n",
    "       The function returns a dictionary containing the metrics 'accuracy', 'precision',\n",
    "       'recall', 'f1' for both training set and validation set.\n",
    "      '''\n",
    "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "      results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "      return [\n",
    "          results['test_accuracy'].mean(), results['test_precision'].mean(), results['test_recall'].mean(), results['test_f1'].mean()\n",
    "      ] \n",
    "\n",
    "     #  return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "     #          \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "     #          \"Training Precision scores\": results['train_precision'],\n",
    "     #          \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "     #          \"Training Recall scores\": results['train_recall'],\n",
    "     #          \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "     #          \"Training F1 scores\": results['train_f1'],\n",
    "     #          \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "     #          \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "     #          \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "     #          \"Validation Precision scores\": results['test_precision'],\n",
    "     #          \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "     #          \"Validation Recall scores\": results['test_recall'],\n",
    "     #          \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "     #          \"Validation F1 scores\": results['test_f1'],\n",
    "     #          \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
    "     #          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cross_validation(estimator, X, y)\n",
      "Cell \u001b[1;32mIn[182], line 28\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(model, _X, _y, _cv)\u001b[0m\n\u001b[0;32m     19\u001b[0m _scoring \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     20\u001b[0m results \u001b[39m=\u001b[39m cross_validate(estimator\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     21\u001b[0m                          X\u001b[39m=\u001b[39m_X,\n\u001b[0;32m     22\u001b[0m                          y\u001b[39m=\u001b[39m_y,\n\u001b[0;32m     23\u001b[0m                          cv\u001b[39m=\u001b[39m_cv,\n\u001b[0;32m     24\u001b[0m                          scoring\u001b[39m=\u001b[39m_scoring,\n\u001b[0;32m     25\u001b[0m                          return_train_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m     27\u001b[0m     results[\u001b[39m'\u001b[39;49m\u001b[39mtest_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmean(), results[\u001b[39m'\u001b[39;49m\u001b[39mtest_precision\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmean(), results[\u001b[39m'\u001b[39;49m\u001b[39mtest_recall\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmean(), results[\u001b[39m'\u001b[39;49m\u001b[39mtest_f1\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mmean()\n\u001b[1;32m---> 28\u001b[0m ]\u001b[39m.\u001b[39;49mmean()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "cross_validation(estimator, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced random forest\n",
    "# {'Training Accuracy scores': array([1., 1., 1., 1., 1.]),\n",
    "#  'Mean Training Accuracy': 100.0,\n",
    "#  'Training Precision scores': array([1., 1., 1., 1., 1.]),\n",
    "#  'Mean Training Precision': 1.0,\n",
    "#  'Training Recall scores': array([1., 1., 1., 1., 1.]),\n",
    "#  'Mean Training Recall': 1.0,\n",
    "#  'Training F1 scores': array([1., 1., 1., 1., 1.]),\n",
    "#  'Mean Training F1 Score': 1.0,\n",
    "#  'Validation Accuracy scores': array([0.90322581, 0.87903226, 0.89430894, 0.86178862, 0.93495935]),\n",
    "#  'Mean Validation Accuracy': 89.46629950170471,\n",
    "#  'Validation Precision scores': array([0.91666667, 0.76923077, 0.90909091, 0.7       , 0.93333333]),\n",
    "#  'Mean Validation Precision': 0.8456643356643356,\n",
    "#  'Validation Recall scores': array([0.5       , 0.45454545, 0.45454545, 0.33333333, 0.66666667]),\n",
    "#  'Mean Validation Recall': 0.4818181818181818,\n",
    "#  'Validation F1 scores': array([0.64705882, 0.57142857, 0.60606061, 0.4516129 , 0.77777778]),\n",
    "#  'Mean Validation F1 Score': 0.6107877364044347}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "# {'Training Accuracy scores': array([1., 1., 1., 1., 1.]),\n",
    "#  'Mean Training Accuracy': 100.0,\n",
    "#  'Training Precision scores': array([1., 1., 1., 1., 1.]),\n",
    "#  'Mean Training Precision': 1.0,\n",
    "#  'Training Recall scores': array([1., 1., 1., 1., 1.]),\n",
    "#  'Mean Training Recall': 1.0,\n",
    "#  'Training F1 scores': array([1., 1., 1., 1., 1.]),\n",
    "#  'Mean Training F1 Score': 1.0,\n",
    "#  'Validation Accuracy scores': array([0.90322581, 0.89516129, 0.91869919, 0.89430894, 0.95121951]),\n",
    "#  'Mean Validation Accuracy': 91.25229478101232,\n",
    "#  'Validation Precision scores': array([1.        , 0.69565217, 0.83333333, 0.78571429, 0.89473684]),\n",
    "#  'Mean Validation Precision': 0.841887327013185,\n",
    "#  'Validation Recall scores': array([0.45454545, 0.72727273, 0.68181818, 0.52380952, 0.80952381]),\n",
    "#  'Mean Validation Recall': 0.6393939393939394,\n",
    "#  'Validation F1 scores': array([0.625     , 0.71111111, 0.75      , 0.62857143, 0.85      ]),\n",
    "#  'Mean Validation F1 Score': 0.7129365079365079}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "# {'Training Accuracy scores': array([0.94726166, 0.94117647, 0.93927126, 0.95951417, 0.93927126]),\n",
    "#  'Mean Training Accuracy': 94.52989628072366,\n",
    "#  'Training Precision scores': array([0.89473684, 0.87012987, 0.88888889, 0.93506494, 0.89041096]),\n",
    "#  'Mean Training Precision': 0.8958462990186133,\n",
    "#  'Training Recall scores': array([0.79069767, 0.77906977, 0.74418605, 0.82758621, 0.74712644]),\n",
    "#  'Mean Training Recall': 0.7777332264100508,\n",
    "#  'Training F1 scores': array([0.83950617, 0.82208589, 0.81012658, 0.87804878, 0.8125    ]),\n",
    "#  'Mean Training F1 Score': 0.8324534850352687,\n",
    "#  'Validation Accuracy scores': array([0.85483871, 0.91129032, 0.88617886, 0.85365854, 0.89430894]),\n",
    "#  'Mean Validation Accuracy': 88.00550747442959,\n",
    "#  'Validation Precision scores': array([0.625     , 0.82352941, 0.72222222, 0.58823529, 0.7       ]),\n",
    "#  'Mean Validation Precision': 0.691797385620915,\n",
    "#  'Validation Recall scores': array([0.45454545, 0.63636364, 0.59090909, 0.47619048, 0.66666667]),\n",
    "#  'Mean Validation Recall': 0.5649350649350648,\n",
    "#  'Validation F1 scores': array([0.52631579, 0.71794872, 0.65      , 0.52631579, 0.68292683]),\n",
    "#  'Mean Validation F1 Score': 0.6207014252328757}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced logistic regression\n",
    "# {'Training Accuracy scores': array([0.9168357 , 0.92697769, 0.93319838, 0.93927126, 0.92510121]),\n",
    "#  'Mean Training Accuracy': 92.82768475252729,\n",
    "#  'Training Precision scores': array([0.69230769, 0.72321429, 0.73873874, 0.76146789, 0.71186441]),\n",
    "#  'Mean Training Precision': 0.7255186026897269,\n",
    "#  'Training Recall scores': array([0.94186047, 0.94186047, 0.95348837, 0.95402299, 0.96551724]),\n",
    "#  'Mean Training Recall': 0.9513499064421278,\n",
    "#  'Training F1 scores': array([0.79802956, 0.81818182, 0.83248731, 0.84693878, 0.8195122 ]),\n",
    "#  'Mean Training F1 Score': 0.8230299310217779,\n",
    "#  'Validation Accuracy scores': array([0.85483871, 0.87903226, 0.84552846, 0.86178862, 0.8699187 ]),\n",
    "#  'Mean Validation Accuracy': 86.22213480199319,\n",
    "#  'Validation Precision scores': array([0.57142857, 0.62962963, 0.55172414, 0.57142857, 0.58064516]),\n",
    "#  'Mean Validation Precision': 0.5809712143416259,\n",
    "#  'Validation Recall scores': array([0.72727273, 0.77272727, 0.72727273, 0.76190476, 0.85714286]),\n",
    "#  'Mean Validation Recall': 0.7692640692640693,\n",
    "#  'Validation F1 scores': array([0.64      , 0.69387755, 0.62745098, 0.65306122, 0.69230769]),\n",
    "#  'Mean Validation F1 Score': 0.6613394896420106}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
